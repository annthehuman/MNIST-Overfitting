Задача:
Добиться от классификатора на MNIST переобучения за счет изменения архитектуры и гиперпараметров.

Ход решения:
Сначала чтобы добиться переобучения я сделала три сетки:
- без параметров
- с большим количеством нейронов не внутреннем слое (10024)
- с маленькой лямбдой для l2 регуляризации. 
Обучала все три сетки на большом количестве эпох - 200. Но все эти попытки не привели к переобучению, а привели к точности на тестовых данных в 95%.

Потом я решила отсортировать трейновый датасет, чтобы сначала были все 0, потом все 1 и так далее. 
В этот раз удалось получить второй гребень на графике для теста и трейна, так что видимо неправильно подготовленный датасет соработал.

![accuracy]([http://url/to/img.png](https://github.com/annthehuman/MNIST-Overfitting/blob/main/accuracy.png?raw=tru))
![error]([http://url/to/img.png](https://github.com/annthehuman/MNIST-Overfitting/blob/main/error.png?raw=tru))
